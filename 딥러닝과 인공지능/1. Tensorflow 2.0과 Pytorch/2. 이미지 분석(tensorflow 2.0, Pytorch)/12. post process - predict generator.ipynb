{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is the full model w/o custom layers\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
    "              loss='sparse_categorical_crossentropy',  # Loss Function \n",
    "              metrics=['accuracy'])  # Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = glob('dataset/cifar/train/*.png')[:100]\n",
    "test_paths = glob('dataset/cifar/test/*.png')[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(path):\n",
    "    return path.split('_')[-1].replace('.png', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [get_class_name(path) for path in train_paths]\n",
    "class_names = np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    fname = tf.strings.split(path, '_')[-1]\n",
    "    lbl_name = tf.strings.regex_replace(fname, '.png', '')\n",
    "    onehot = tf.cast(lbl_name == class_names, tf.uint8)\n",
    "    return tf.argmax(onehot)  # 이번에는 onehot이 아닌 label 번호로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_label(path):\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.cast(image, tf.float32) / 255.  # rescale\n",
    "    \n",
    "    label = get_label(path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, label):\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(image_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 2.5053 - accuracy: 0.1029 - val_loss: 2.3177 - val_accuracy: 0.0938\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 1s 287ms/step - loss: 2.2567 - accuracy: 0.1912 - val_loss: 2.3174 - val_accuracy: 0.0729\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 2.3062 - accuracy: 0.1146 - val_loss: 2.3241 - val_accuracy: 0.0729\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 1s 316ms/step - loss: 2.2321 - accuracy: 0.1471 - val_loss: 2.3243 - val_accuracy: 0.0729\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 1s 340ms/step - loss: 2.2539 - accuracy: 0.0882 - val_loss: 2.3436 - val_accuracy: 0.0729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2783ad77748>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(test_paths) // batch_size\n",
    "\n",
    "model.fit_generator(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지를 Load 직접 load해서 넣는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/cifar/test\\\\0_cat.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = test_paths[0] # 예제 이미지\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image 불러오는 방법\n",
    "gfile = tf.io.read_file(path)\n",
    "image = tf.io.decode_image(gfile, dtype=tf.float32)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predict할 때 batch size가 있어야 돼. 단일 이미지로는 predict 불가\n",
    "# 왜냐면 4차원으로 넣어서 학습을 돌렸기때문에 predict도 4차원으로 맞춰줘야 돼\n",
    "image = image[tf.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 32, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape # 이미지 1개 넣은 상태\n",
    "# (1, 10) -> 이미지 1개에 대한 pred 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09366836, 0.08083295, 0.11359921, 0.09158107, 0.12679616,\n",
       "        0.06811095, 0.11320259, 0.09504919, 0.13555591, 0.08160356]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred) # 정답을 8로 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator에서 데이터를 가져오는 방법\n",
    "- path를 따로 불러오는 방법 말고도 generator를 넣어서 불러오는 방법도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image, test_label = next(iter(test_dataset)) # 하나만 가져옴(batch 묶음 1개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 32, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generator를 이용하여 데이터를 가져오면 앞에서처럼 차원 수 하나 더 늘려줄 작업 필요x\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict는 image만!\n",
    "pred = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape # batch size만큼의 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09366836, 0.08083296, 0.11359921, 0.09158107, 0.12679616,\n",
       "       0.06811094, 0.1132026 , 0.09504919, 0.13555591, 0.08160356],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator에 넣는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in test_dataset.take(1): # 1개의 batch만 가져옴\n",
    "    plt.imshow(image[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(test_dataset.take(1)) # 1개의 batch만 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_generator(test_dataset.take(2))\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 32, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = next(iter(test_dataset))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "32/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 2.3514 - accuracy: 0.1250\n"
     ]
    }
   ],
   "source": [
    "# evaluate은 image와 label 같이 넣는다!\n",
    "evals = model.evaluate(image, label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.3514249324798584, 0.125]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
