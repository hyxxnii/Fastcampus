{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반복 실험을 위한 Sacred\n",
    "- [Sacred Github](https://github.com/IDSIA/sacred)\n",
    "- Sacred란?\n",
    "    - Sacred is a tool to help you configure, organize, log and reproduce experiments developed at IDSIA\n",
    "    - 머신러닝 모델링을 진행할 때 설정을 저장해주고 관리하는 것을 도와주는 도구\n",
    "- 왜 필요한가요?\n",
    "    - Kaggle에서 자주 발생하는 예시\n",
    "        - 사용한 Feature는?\n",
    "        - 사용한 파라미터는?\n",
    "        - 그 결과는?\n",
    "    - 다양한 실험을 빠르게 진행하며, 손으로 기록하지 않고 자동으로 기록될 수 있도록 도와줄 도구가 필요\n",
    "- Scratch로 구현하면?\n",
    "    - Logger를 정의해서 필요할 때마다 Logger에 Feature, 파라미터 등을 저장\n",
    "    - 값을 보기 위해 Logger를 Parsing\n",
    "- Sacred는 위 방법을 데코레이터로 쉽게 사용할 수 있도록 도와줌\n",
    "    - MLOps와 관련되는 부분으로, 국내의 다양한 머신러닝 강의에서 이런 부분을 다루지 않아 추가!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sacred의 Main mechanisms\n",
    "    - ConfigScopes : 함수의 local 변수를 편리하게 다룰 수 있음 @ex.config 데코레이터로 사용\n",
    "    - Config Injection : 모든 함수에 있는 설정을 접근할 수 있음\n",
    "    - Command-line interface : 커맨드 라인으로 파라미터를 바꿔서 실행할 수 있음\n",
    "    - Observers : 실험의 모든 정보를 Observers에게 제공해 저장. MongoDB / S3 등 => 이번 강의에선 그냥 로컬에 저장\n",
    "    - Automatic seeding : 실험의 무작위를 컨트롤할 때 도와줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacred\n",
      "  Downloading sacred-0.8.1.tar.gz (90 kB)\n",
      "Collecting docopt<1.0,>=0.3\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting jsonpickle<2.0,>=1.2\n",
      "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting munch<3.0,>=2.0.2\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.0 in c:\\users\\hyun\\lib\\site-packages (from sacred) (1.11.2)\n",
      "Collecting py-cpuinfo>=4.0\n",
      "  Downloading py-cpuinfo-7.0.0.tar.gz (95 kB)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\hyun\\lib\\site-packages (from sacred) (0.4.1)\n",
      "Requirement already satisfied: packaging>=18.0 in c:\\users\\hyun\\lib\\site-packages (from sacred) (19.2)\n",
      "Collecting GitPython\n",
      "  Downloading GitPython-3.1.11-py3-none-any.whl (159 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hyun\\lib\\site-packages (from jsonpickle<2.0,>=1.2->sacred) (0.23)\n",
      "Requirement already satisfied: six in c:\\users\\hyun\\lib\\site-packages (from munch<3.0,>=2.0.2->sacred) (1.13.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\hyun\\lib\\site-packages (from packaging>=18.0->sacred) (2.4.5)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.5-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hyun\\lib\\site-packages (from importlib-metadata->jsonpickle<2.0,>=1.2->sacred) (0.6.0)\n",
      "Collecting smmap<4,>=3.0.1\n",
      "  Downloading smmap-3.0.4-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\hyun\\lib\\site-packages (from zipp>=0.5->importlib-metadata->jsonpickle<2.0,>=1.2->sacred) (7.2.0)\n",
      "Building wheels for collected packages: sacred, docopt, py-cpuinfo\n",
      "  Building wheel for sacred (setup.py): started\n",
      "  Building wheel for sacred (setup.py): finished with status 'done'\n",
      "  Created wheel for sacred: filename=sacred-0.8.1-py2.py3-none-any.whl size=105022 sha256=5908309a1d159d1ad253c7cb19c64da7d73bc8cb814a04c822132b4c66dec534\n",
      "  Stored in directory: c:\\users\\영현\\appdata\\local\\pip\\cache\\wheels\\3c\\ac\\e1\\2f746c47edc95a1cf43119706c787efd9c307a8b3d4a649308\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13709 sha256=e2940faf40925ad73867186882f4864e68bcb6976c717592a2ebb332798d84b6\n",
      "  Stored in directory: c:\\users\\영현\\appdata\\local\\pip\\cache\\wheels\\72\\b0\\3f\\1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "  Building wheel for py-cpuinfo (setup.py): started\n",
      "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-py3-none-any.whl size=20074 sha256=62407f3a5dc7ef2ebd506f1273f9fd414bfca48b331390f491682e1538783e54\n",
      "  Stored in directory: c:\\users\\영현\\appdata\\local\\pip\\cache\\wheels\\d7\\59\\0d\\58c5e576d9192261fa3da00466eebe6f7a1ac1873a7ab1f2ce\n",
      "Successfully built sacred docopt py-cpuinfo\n",
      "Installing collected packages: docopt, jsonpickle, munch, py-cpuinfo, smmap, gitdb, GitPython, sacred\n",
      "Successfully installed GitPython-3.1.11 docopt-0.6.2 gitdb-4.0.5 jsonpickle-1.4.1 munch-2.5.0 py-cpuinfo-7.0.0 sacred-0.8.1 smmap-3.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hyun\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sacred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공식 홈페이지 Sacred 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "from numpy.random import permutation\n",
    "from sklearn import svm, datasets\n",
    "from sacred import Experiment\n",
    "from sacred.observers import FileStorageObserver\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "PROJECT_ID='nyc-taxi-demand-predict' # 여기에 여러분들의 프로젝트 ID를 넣어주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook에선 interactive=True 지정해줘야 하고, 스크립트 형식이라면 이 옵션이 필요 없음\n",
    "ex = Experiment('iris_rbf_svm', interactive=True)\n",
    "# Experiment: 실험 객체를 만들어줘야해\n",
    "\n",
    "# Decorator로 config 저장\n",
    "@ex.config\n",
    "def cfg():\n",
    "    C = 1.0\n",
    "    gamma = 0.7\n",
    "\n",
    "# ex.main을 지정 => 이 때 cfg에 있는 인자들이 자동으로 injection됨\n",
    "# 또한 Notebook에선 ex.main을 쓰고 스크립트 파일에선 ex.automain을 사용\n",
    "@ex.main\n",
    "def run(C, gamma):\n",
    "    iris = datasets.load_iris()\n",
    "    per = permutation(iris.target.size)\n",
    "    iris.data = iris.data[per]\n",
    "    iris.target = iris.target[per]\n",
    "    clf = svm.SVC(C, 'rbf', gamma=gamma)\n",
    "    clf.fit(iris.data[:90],\n",
    "          iris.target[:90])\n",
    "    return clf.score(iris.data[90:],\n",
    "                   iris.target[90:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - iris_rbf_svm - No observers have been added to this run\n",
      "INFO - iris_rbf_svm - Running command 'run'\n",
      "INFO - iris_rbf_svm - Started\n",
      "INFO - iris_rbf_svm - Result: 0.9833333333333333\n",
      "INFO - iris_rbf_svm - Completed after 0:00:00\n"
     ]
    }
   ],
   "source": [
    "run_result = ex.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'gamma': 0.7, 'seed': 969061621}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_result.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_result.result\n",
    "# score return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'iris_rbf_svm',\n",
       " 'base_dir': 'C:\\\\Users\\\\영현\\\\STUDY\\\\Fast Campus\\\\머신러닝과 데이터분석 A-Z\\\\8. 실전프로젝트\\\\3. 뉴욕(NYC) 택시 수요 예측',\n",
       " 'sources': [],\n",
       " 'dependencies': ['ipython==7.9.0',\n",
       "  'ipywidgets==7.5.1',\n",
       "  'matplotlib==3.2.1',\n",
       "  'numpy==1.17.4',\n",
       "  'pandas==0.25.3',\n",
       "  'sacred==0.8.1',\n",
       "  'scikit-learn==0.22.2.post1',\n",
       "  'seaborn==0.9.0'],\n",
       " 'repositories': [],\n",
       " 'mainfile': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_result.experiment_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존 프로젝트에 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Experiment('nyc-demand-prediction', interactive=True)\n",
    "\n",
    "# experiment_dir가 없으면 폴더 생성하고 FileStorageObserver로 저장\n",
    "experiment_dir = os.path.join('./', 'experiments')\n",
    "if not os.path.isdir(experiment_dir): \n",
    "    os.makedirs(experiment_dir)\n",
    "ex.observers.append(FileStorageObserver.create(experiment_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - google.cloud.bigquery.opentelemetry_tracing - This service is instrumented using OpenTelemetry. OpenTelemetry could not be imported; please add opentelemetry-api and opentelemetry-instrumentation packages in order to get BigQuery Tracing data.\n",
      "WARNING - google.auth.compute_engine._metadata - Compute Engine Metadata server unavailable onattempt 1 of 3. Reason: timed out\n",
      "WARNING - google.auth.compute_engine._metadata - Compute Engine Metadata server unavailable onattempt 2 of 3. Reason: timed out\n",
      "WARNING - google.auth.compute_engine._metadata - Compute Engine Metadata server unavailable onattempt 3 of 3. Reason: timed out\n",
      "WARNING - google.auth._default - Authentication failed using Compute Engine authentication due to unavailable metadata server.\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████| 87020/87020 [00:07<00:00, 10886.17rows/s]\n",
      "INFO - pandas_gbq.gbq - Total time taken 10.67 s.\n",
      "Finished at 2020-12-03 14:55:03.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_query = \"\"\"\n",
    "WITH base_data AS \n",
    "(\n",
    "  SELECT nyc_taxi.*, gis.* EXCEPT (zip_code_geom)\n",
    "  FROM (\n",
    "    SELECT *\n",
    "    FROM `bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2015`\n",
    "    WHERE \n",
    "        EXTRACT(MONTH from pickup_datetime) = 1\n",
    "        and pickup_latitude  <= 90 and pickup_latitude >= -90\n",
    "    ) AS nyc_taxi\n",
    "  JOIN (\n",
    "    SELECT zip_code, state_code, state_name, city, county, zip_code_geom\n",
    "    FROM `bigquery-public-data.geo_us_boundaries.zip_codes`\n",
    "    WHERE state_code='NY'\n",
    "    ) AS gis \n",
    "  ON ST_CONTAINS(zip_code_geom, st_geogpoint(pickup_longitude, pickup_latitude))\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    zip_code,\n",
    "    DATETIME_TRUNC(pickup_datetime, hour) as pickup_hour,\n",
    "    EXTRACT(MONTH FROM pickup_datetime) AS month,\n",
    "    EXTRACT(DAY FROM pickup_datetime) AS day,\n",
    "    CAST(format_datetime('%u', pickup_datetime) AS INT64) -1 AS weekday,\n",
    "    EXTRACT(HOUR FROM pickup_datetime) AS hour,\n",
    "    CASE WHEN CAST(FORMAT_DATETIME('%u', pickup_datetime) AS INT64) IN (6, 7) THEN 1 ELSE 0 END AS is_weekend,\n",
    "    COUNT(*) AS cnt\n",
    "FROM base_data \n",
    "GROUP BY zip_code, pickup_hour, month, day, weekday, hour, is_weekend\n",
    "ORDER BY pickup_hour\n",
    "\"\"\"\n",
    "\n",
    "base_df = pd.read_gbq(query=base_query, dialect='standard', project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10037</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10170</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11238</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code pickup_hour  month  day  weekday  hour  is_weekend  cnt\n",
       "0    10037  2015-01-01      1    1        3     0           0   26\n",
       "1    10170  2015-01-01      1    1        3     0           0   44\n",
       "2    11238  2015-01-01      1    1        3     0           0   95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.head(3)\n",
    "# cnt: target feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feautre Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(base_df[['zip_code']])\n",
    "ohe_output = enc.transform(base_df[['zip_code']]).toarray()\n",
    "ohe_df = pd.concat([base_df, pd.DataFrame(ohe_output, columns='zip_code_'+enc.categories_[0])], axis=1)\n",
    "ohe_df['log_cnt'] = np.log10(ohe_df['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_test(df, date):\n",
    "    \"\"\"\n",
    "    Dataframe에서 train_df, test_df로 나눠주는 함수\n",
    "    \n",
    "    df : 시계열 데이터 프레임\n",
    "    date : 기준점 날짜\n",
    "    \"\"\"\n",
    "    train_df = df[df['pickup_hour'] < date]\n",
    "    test_df = df[df['pickup_hour'] >= date]\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_train_and_test(ohe_df, '2015-01-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>cnt</th>\n",
       "      <th>zip_code_10001</th>\n",
       "      <th>zip_code_10002</th>\n",
       "      <th>...</th>\n",
       "      <th>zip_code_12729</th>\n",
       "      <th>zip_code_12771</th>\n",
       "      <th>zip_code_13029</th>\n",
       "      <th>zip_code_13118</th>\n",
       "      <th>zip_code_13656</th>\n",
       "      <th>zip_code_13691</th>\n",
       "      <th>zip_code_14072</th>\n",
       "      <th>zip_code_14527</th>\n",
       "      <th>zip_code_14801</th>\n",
       "      <th>log_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65113</th>\n",
       "      <td>11415</td>\n",
       "      <td>2015-01-23 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65114</th>\n",
       "      <td>10040</td>\n",
       "      <td>2015-01-23 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65115</th>\n",
       "      <td>10271</td>\n",
       "      <td>2015-01-23 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65116</th>\n",
       "      <td>11204</td>\n",
       "      <td>2015-01-23 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65117</th>\n",
       "      <td>11356</td>\n",
       "      <td>2015-01-23 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      zip_code         pickup_hour  month  day  weekday  hour  is_weekend  \\\n",
       "65113    11415 2015-01-23 23:00:00      1   23        4    23           0   \n",
       "65114    10040 2015-01-23 23:00:00      1   23        4    23           0   \n",
       "65115    10271 2015-01-23 23:00:00      1   23        4    23           0   \n",
       "65116    11204 2015-01-23 23:00:00      1   23        4    23           0   \n",
       "65117    11356 2015-01-23 23:00:00      1   23        4    23           0   \n",
       "\n",
       "       cnt  zip_code_10001  zip_code_10002  ...  zip_code_12729  \\\n",
       "65113    1             0.0             0.0  ...             0.0   \n",
       "65114    2             0.0             0.0  ...             0.0   \n",
       "65115    1             0.0             0.0  ...             0.0   \n",
       "65116    1             0.0             0.0  ...             0.0   \n",
       "65117    1             0.0             0.0  ...             0.0   \n",
       "\n",
       "       zip_code_12771  zip_code_13029  zip_code_13118  zip_code_13656  \\\n",
       "65113             0.0             0.0             0.0             0.0   \n",
       "65114             0.0             0.0             0.0             0.0   \n",
       "65115             0.0             0.0             0.0             0.0   \n",
       "65116             0.0             0.0             0.0             0.0   \n",
       "65117             0.0             0.0             0.0             0.0   \n",
       "\n",
       "       zip_code_13691  zip_code_14072  zip_code_14527  zip_code_14801  log_cnt  \n",
       "65113             0.0             0.0             0.0             0.0  0.00000  \n",
       "65114             0.0             0.0             0.0             0.0  0.30103  \n",
       "65115             0.0             0.0             0.0             0.0  0.00000  \n",
       "65116             0.0             0.0             0.0             0.0  0.00000  \n",
       "65117             0.0             0.0             0.0             0.0  0.00000  \n",
       "\n",
       "[5 rows x 383 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용하지 않을 컬럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['zip_code']\n",
    "del train_df['pickup_hour']\n",
    "del test_df['zip_code']\n",
    "del test_df['pickup_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>cnt</th>\n",
       "      <th>zip_code_10001</th>\n",
       "      <th>zip_code_10002</th>\n",
       "      <th>zip_code_10003</th>\n",
       "      <th>zip_code_10004</th>\n",
       "      <th>...</th>\n",
       "      <th>zip_code_12729</th>\n",
       "      <th>zip_code_12771</th>\n",
       "      <th>zip_code_13029</th>\n",
       "      <th>zip_code_13118</th>\n",
       "      <th>zip_code_13656</th>\n",
       "      <th>zip_code_13691</th>\n",
       "      <th>zip_code_14072</th>\n",
       "      <th>zip_code_14527</th>\n",
       "      <th>zip_code_14801</th>\n",
       "      <th>log_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.414973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.643453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  day  weekday  hour  is_weekend  cnt  zip_code_10001  zip_code_10002  \\\n",
       "0      1    1        3     0           0   26             0.0             0.0   \n",
       "1      1    1        3     0           0   44             0.0             0.0   \n",
       "\n",
       "   zip_code_10003  zip_code_10004  ...  zip_code_12729  zip_code_12771  \\\n",
       "0             0.0             0.0  ...             0.0             0.0   \n",
       "1             0.0             0.0  ...             0.0             0.0   \n",
       "\n",
       "   zip_code_13029  zip_code_13118  zip_code_13656  zip_code_13691  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   zip_code_14072  zip_code_14527  zip_code_14801   log_cnt  \n",
       "0             0.0             0.0             0.0  1.414973  \n",
       "1             0.0             0.0             0.0  1.643453  \n",
       "\n",
       "[2 rows x 381 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw = train_df.pop('cnt')\n",
    "y_train_log = train_df.pop('log_cnt')\n",
    "y_test_raw = test_df.pop('cnt')\n",
    "y_test_log = test_df.pop('log_cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test_raw.values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.copy()\n",
    "x_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    score = pd.DataFrame([mape, mae, mse], index=['mape', 'mae', 'mse'], columns=['score']).T\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 설정\n",
    "- 위에서 ex = Experiment('nyc-demand-prediction', interactive=True)했는데, ex.config로 설정을 저장\n",
    "- ex.capture는 해당 설정을 사용해 함수를 리턴\n",
    "- ex.main은 실험이 실행될 때 진행할 내용을 담음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config\n",
    "def config():\n",
    "    fit_intercept=True\n",
    "    normalize=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.capture\n",
    "def get_model(fit_intercept, normalize):\n",
    "    return LinearRegression(fit_intercept, normalize)\n",
    "\n",
    "# capture: 함수를 만들어서 기입을 할 수 있는 decorate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _log과 _run은 별도로 정의하지 않아도 함수의 인자로 사용 가능\n",
    "@ex.main\n",
    "def run(_log, _run):\n",
    "    lr_reg = get_model() # 인자 안넣어도 돼 (config에서 설정해줬기때문)\n",
    "    lr_reg.fit(x_train, y_train_raw)\n",
    "    pred = lr_reg.predict(x_test)\n",
    "    # log File에 로그 저장\n",
    "    _log.info(\"Predict End\")\n",
    "    score = evaluation(y_test_raw, pred)\n",
    "    _run.log_scalar('model_name', lr_reg.__class__.__name__)\n",
    "    \n",
    "    # Metrics쪽에 저장하고 싶으면 아래처럼 사용 (추천)\n",
    "    _run.log_scalar('metrics', score)\n",
    "    \n",
    "    # Result쪽에 저장하고 싶으면 아래처럼 사용\n",
    "    return score.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - nyc-demand-prediction - Running command 'run'\n",
      "INFO - nyc-demand-prediction - Started run with ID \"2\"\n",
      "INFO - run - Predict End\n",
      "INFO - nyc-demand-prediction - Result: {'mape': {'score': 225017760230.73145}, 'mae': {'score': 2300181639.6865945}, 'mse': {'score': 5.038255261890111e+21}}\n",
      "INFO - nyc-demand-prediction - Completed after 0:00:04\n"
     ]
    }
   ],
   "source": [
    "experiment_result = ex.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True, 'normalize': False, 'seed': 696760466}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_result.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 확인하기 위한 Parser\n",
    "- Experiment에서 log찍는 방식에 따라 사용할 함수가 다름\n",
    "    - 1) \\_run.log\\_scalar에 metrics을 저장하는 경우 : 추천\n",
    "    - 2) @ex.main의 함수에 결과를 return하는 경우 \n",
    "        - 위 결과는 1,2번 둘 다 되어있는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) _run.log_scalar에 metrics을 저장하는 경우\n",
    "def parsing_output(ex_id):\n",
    "    with open(f'./experiments/{ex_id}/metrics.json') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    with open(f'./experiments/{ex_id}/config.json') as config_file:\n",
    "        config_data = json.load(config_file)\n",
    "    with open(f'./experiments/{ex_id}/run.json') as run_file:\n",
    "        run_data = json.load(run_file)\n",
    "    \n",
    "    output_df = pd.DataFrame(json_data['model_name']['values'], columns=['model_name'], index=['score'])\n",
    "    output_df['experiment_num'] = ex_id\n",
    "    output_df['config'] = str(config_data)\n",
    "    run_df = pd.DataFrame(run_data['result'])\n",
    "    output_df = pd.concat([output_df, run_df], axis=1)\n",
    "    output_df = output_df.round(2)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) @ex.main의 함수에 결과를 return하는 경우\n",
    "def parsing_output(ex_id):\n",
    "    with open(f'./experiments/{ex_id}/run.json') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    output = pd.DataFrame(json_data['result'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>experiment_num</th>\n",
       "      <th>config</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>{'fit_intercept': True, 'normalize': False, 's...</td>\n",
       "      <td>2.300182e+09</td>\n",
       "      <td>2.250178e+11</td>\n",
       "      <td>5.038255e+21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name  experiment_num  \\\n",
       "score  LinearRegression               2   \n",
       "\n",
       "                                                  config           mae  \\\n",
       "score  {'fit_intercept': True, 'normalize': False, 's...  2.300182e+09   \n",
       "\n",
       "               mape           mse  \n",
       "score  2.250178e+11  5.038255e+21  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing_output(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더 자세한 내용이 궁금하면\n",
    "- [Sacred Github](https://github.com/IDSIA/sacred)\n",
    "- [머신러닝 실험을 도와줄 Python Sacred 소개](https://zzsza.github.io/mlops/2019/07/21/python-sacred/)\n",
    "- [Sacred와 Omniboard를 활용한 실험 및 로그 모니터링](https://zzsza.github.io/mlops/2019/07/22/sacred-with-omniboard/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
