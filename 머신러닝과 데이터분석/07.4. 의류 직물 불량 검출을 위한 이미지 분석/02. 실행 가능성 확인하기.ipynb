{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실행 가능성 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "DATASET_PATH = 'data/2/'\n",
    "DATASET_OK_PATTERN = DATASET_PATH + 'OK/*.png'\n",
    "DATASET_FAIL_PATTERN = DATASET_PATH + 'FAIL/*.png'\n",
    "\n",
    "RESULT_SAVE_PATH = 'results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순한 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    return Sequential([Conv2D(32, (3,3), activation='relu'),\n",
    "                      MaxPool2D(),\n",
    "                      Conv2D(64, (3,3), activation='relu'),\n",
    "                      MaxPool2D(),\n",
    "                      Conv2D(128, (3,3), activation='relu'),\n",
    "                      MaxPool2D(),\n",
    "                      Conv2D(256, (3,3), activation='relu'),\n",
    "                      MaxPool2D(),\n",
    "                      Flatten(),\n",
    "                      Dense(1, activation='sigmoid')] # binary clf니까 sigmoid 사용\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name을 불러오고 png로 저장되어있기때문에 256x256로 풀어주는 디코딩하는 작업\n",
    "def preprocess(file_name):\n",
    "    img = tf.io.read_file(file_name) # 내용을 binary로 읽어옴\n",
    "    img = tf.image.decode_png(img) # png는 channel입력 안 받음(image는 받음)\n",
    "    return tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # 읽어올 때는 uint8으로 읽어오는데 그것을 float32형태로 변환해서 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_list = glob.glob(DATASET_OK_PATTERN)\n",
    "#print(ok_list)\n",
    "# glob사용하면 pattern으로 되어있는 파일들을 쭉 읽어서 리스트 형태로 파일 저장\n",
    "# os.listdir()을 사용하면 'data/2/OK'가 빠진 상태로 저장되고, 파일 이름 뒤에 '.png'도 지정해줄 수 없어서 불편함\n",
    "\n",
    "ds_ok = tf.data.Dataset.list_files(ok_list)     # 양품 : 0\n",
    "ds_ok_label = tf.data.Dataset.from_tensor_slices([0] * len(ok_list)) # 0/1 label중 어떤 label인지 설정\n",
    "# 또는 [0 for _ in range(len(ok_list))]\n",
    "\n",
    "ds_ok = ds_ok.map(preprocess)\n",
    "ds_ok = tf.data.Dataset.zip((ds_ok, ds_ok_label)) # zip -> 이미지만 출력했다면 label도 같이 출력하게끔\n",
    "\n",
    "\n",
    "fail_list = glob.glob(DATASET_FAIL_PATTERN)\n",
    "\n",
    "ds_fail = tf.data.Dataset.list_files(fail_list)   # 불량 : 1\n",
    "ds_fail_label = tf.data.Dataset.from_tensor_slices([1] * len(fail_list))\n",
    "\n",
    "ds_fail = ds_fail.map(preprocess)\n",
    "ds_fail = tf.data.Dataset.zip((ds_fail, ds_fail_label))\n",
    "\n",
    "ds = tf.data.Dataset.concatenate(ds_ok, ds_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Valid 데이터셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_size = len(ok_list) + len(fail_list)\n",
    "train_size = int(ds_size * 0.7)\n",
    "\n",
    "ds = ds.shuffle(ds_size) # 얼만큼을 모아서 shufflt해줄 것이냐 -> 전체 데이터를 다 섞자\n",
    "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration=True).batch(32) # train_size 크기만큼 가져와서 1024개의 버퍼사이즈를 가지고 매 epoch 돌때마다 shuffle\n",
    "ds_valid = ds.skip(train_size).batch(32) # take대신 skip -> 그만큼 skip해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 21 steps, validate for 9 steps\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - 112s 5s/step - loss: 0.4154 - accuracy: 0.8427 - val_loss: 0.4102 - val_accuracy: 0.8556\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 135s 6s/step - loss: 0.4215 - accuracy: 0.8669 - val_loss: 0.3883 - val_accuracy: 0.8768\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 125s 6s/step - loss: 0.3765 - accuracy: 0.8880 - val_loss: 0.4336 - val_accuracy: 0.8521\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 82s 4s/step - loss: 0.3665 - accuracy: 0.8729 - val_loss: 0.3373 - val_accuracy: 0.8697\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 101s 5s/step - loss: 0.3428 - accuracy: 0.8805 - val_loss: 0.3842 - val_accuracy: 0.8627\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 82s 4s/step - loss: 0.3196 - accuracy: 0.8880 - val_loss: 0.3561 - val_accuracy: 0.8803\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 91s 4s/step - loss: 0.3627 - accuracy: 0.8684 - val_loss: 0.3908 - val_accuracy: 0.8732\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 85s 4s/step - loss: 0.3309 - accuracy: 0.8835 - val_loss: 0.3494 - val_accuracy: 0.8873\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 117s 6s/step - loss: 0.3371 - accuracy: 0.8805 - val_loss: 0.3154 - val_accuracy: 0.8908\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 113s 5s/step - loss: 0.3307 - accuracy: 0.8835 - val_loss: 0.3441 - val_accuracy: 0.8697\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 107s 5s/step - loss: 0.3581 - accuracy: 0.8729 - val_loss: 0.2492 - val_accuracy: 0.9190\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 126s 6s/step - loss: 0.3548 - accuracy: 0.8684 - val_loss: 0.3815 - val_accuracy: 0.8556\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 110s 5s/step - loss: 0.3269 - accuracy: 0.8729 - val_loss: 0.3354 - val_accuracy: 0.8697\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 106s 5s/step - loss: 0.3440 - accuracy: 0.8759 - val_loss: 0.3484 - val_accuracy: 0.8803\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 107s 5s/step - loss: 0.3151 - accuracy: 0.8880 - val_loss: 0.3067 - val_accuracy: 0.8873\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 97s 5s/step - loss: 0.3292 - accuracy: 0.8699 - val_loss: 0.3386 - val_accuracy: 0.8592\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 108s 5s/step - loss: 0.3065 - accuracy: 0.8820 - val_loss: 0.2750 - val_accuracy: 0.9120\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 108s 5s/step - loss: 0.3093 - accuracy: 0.8775 - val_loss: 0.3255 - val_accuracy: 0.8768\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 104s 5s/step - loss: 0.2959 - accuracy: 0.8850 - val_loss: 0.3907 - val_accuracy: 0.8662\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 91s 4s/step - loss: 0.3029 - accuracy: 0.8896 - val_loss: 0.2992 - val_accuracy: 0.8803\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 101s 5s/step - loss: 0.3022 - accuracy: 0.8850 - val_loss: 0.7700 - val_accuracy: 0.7887\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 109s 5s/step - loss: 0.4291 - accuracy: 0.8533 - val_loss: 0.4023 - val_accuracy: 0.8592\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 106s 5s/step - loss: 0.3608 - accuracy: 0.8805 - val_loss: 0.3877 - val_accuracy: 0.8662\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 102s 5s/step - loss: 0.3669 - accuracy: 0.8805 - val_loss: 0.3852 - val_accuracy: 0.8662\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 81s 4s/step - loss: 0.4102 - accuracy: 0.8578 - val_loss: 0.3932 - val_accuracy: 0.8627\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 100s 5s/step - loss: 0.3519 - accuracy: 0.8835 - val_loss: 0.4129 - val_accuracy: 0.8556\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 131s 6s/step - loss: 0.3800 - accuracy: 0.8729 - val_loss: 0.3578 - val_accuracy: 0.8908\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 84s 4s/step - loss: 0.3977 - accuracy: 0.8669 - val_loss: 0.3966 - val_accuracy: 0.8627\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 89s 4s/step - loss: 0.3797 - accuracy: 0.8714 - val_loss: 0.3601 - val_accuracy: 0.8768\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 118s 6s/step - loss: 0.3633 - accuracy: 0.8744 - val_loss: 0.3932 - val_accuracy: 0.8768\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 87s 4s/step - loss: 0.3612 - accuracy: 0.8790 - val_loss: 0.3662 - val_accuracy: 0.8697\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 75s 4s/step - loss: 0.3531 - accuracy: 0.8744 - val_loss: 0.4395 - val_accuracy: 0.8451\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 84s 4s/step - loss: 0.3421 - accuracy: 0.8820 - val_loss: 0.3331 - val_accuracy: 0.8838\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 96s 5s/step - loss: 0.3352 - accuracy: 0.8835 - val_loss: 0.3111 - val_accuracy: 0.8803\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 116s 6s/step - loss: 0.3477 - accuracy: 0.8669 - val_loss: 0.2985 - val_accuracy: 0.8803\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 110s 5s/step - loss: 0.3239 - accuracy: 0.8654 - val_loss: 0.3403 - val_accuracy: 0.8838\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 108s 5s/step - loss: 0.3478 - accuracy: 0.8623 - val_loss: 0.3349 - val_accuracy: 0.8697\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 112s 5s/step - loss: 0.3367 - accuracy: 0.8805 - val_loss: 0.2797 - val_accuracy: 0.9190\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 129s 6s/step - loss: 0.3126 - accuracy: 0.8896 - val_loss: 0.3195 - val_accuracy: 0.8662\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 117s 6s/step - loss: 0.3365 - accuracy: 0.8790 - val_loss: 0.3248 - val_accuracy: 0.8838\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 105s 5s/step - loss: 0.3218 - accuracy: 0.8835 - val_loss: 0.3295 - val_accuracy: 0.8838\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 116s 6s/step - loss: 0.3419 - accuracy: 0.8684 - val_loss: 0.3457 - val_accuracy: 0.8732\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 113s 5s/step - loss: 0.3406 - accuracy: 0.8699 - val_loss: 0.3712 - val_accuracy: 0.8521\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 104s 5s/step - loss: 0.3378 - accuracy: 0.8714 - val_loss: 0.3159 - val_accuracy: 0.8732\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 90s 4s/step - loss: 0.3100 - accuracy: 0.8805 - val_loss: 0.2837 - val_accuracy: 0.8979\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 80s 4s/step - loss: 0.3008 - accuracy: 0.8926 - val_loss: 0.3683 - val_accuracy: 0.8521\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 78s 4s/step - loss: 0.3044 - accuracy: 0.8744 - val_loss: 0.3254 - val_accuracy: 0.8873\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 82s 4s/step - loss: 0.3269 - accuracy: 0.8805 - val_loss: 0.2795 - val_accuracy: 0.8838\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 76s 4s/step - loss: 0.3093 - accuracy: 0.8835 - val_loss: 0.3241 - val_accuracy: 0.8697\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 2352s 112s/step - loss: 0.2783 - accuracy: 0.8956 - val_loss: 0.2961 - val_accuracy: 0.8944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15b7f88a208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, validation_data=ds_valid, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과를 이미지로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 결과를 잘 볼 수 있어야 분석할 수 있겠지\n",
    "\n",
    "# 경로 저장\n",
    "def mkdir(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        os.mkdir(path)\n",
    "        \n",
    "mkdir(RESULT_SAVE_PATH)\n",
    "mkdir(RESULT_SAVE_PATH + '/TP') # 실제 불량\n",
    "mkdir(RESULT_SAVE_PATH + '/TN') # 실제 양품\n",
    "mkdir(RESULT_SAVE_PATH + '/FP') # 가짜 불량 (양품인데 불량이라고 분류)\n",
    "mkdir(RESULT_SAVE_PATH + '/FN') # 가짜 양품 (불량인데 양품이라고 분류)\n",
    "\n",
    "# validation data을 돌면서 결과 저장\n",
    "index = 0\n",
    "for imgs, labels in ds_valid:\n",
    "    preds = model.predict(imgs)\n",
    "    for idx in range(imgs.shape[0]): # 32개의 batch size로 돌기때문에 한번에 데이터가 32개가 나오니까 하나씩 사용해주기위해\n",
    "        gt = labels[idx].numpy() # labels은 tensor로 저장해줬기때문에 numpy로 바꿔줘야 파이썬 문법 사용하기 쉽겠지\n",
    "        y = preds[idx]\n",
    "            \n",
    "        # 1 : 불량\n",
    "        if gt == 1 and y > 0.5 : # binary clf는 0.5를 기준으로 하게끔 되어있음\n",
    "            path = RESULT_SAVE_PATH + '/TP'\n",
    "        elif gt == 1 and y <= 0.5 :\n",
    "            path = RESULT_SAVE_PATH + '/FN'\n",
    "        elif gt == 0 and y > 0.5 :\n",
    "            path = RESULT_SAVE_PATH + '/FP'\n",
    "        else :\n",
    "            path = RESULT_SAVE_PATH + '/TN'\n",
    "            \n",
    "        cv2.imwrite(path + '/%.f_%04d.png' % (y, index), imgs[idx].numpy() * 255) # img에 255를 곱해줘야 cv에서 이미지 저장됨  \n",
    "        index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
