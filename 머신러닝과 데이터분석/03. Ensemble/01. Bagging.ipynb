{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression과 Classification 두 모델 이용해서 Bagging 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  floors  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00     1.0   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25     2.0   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00     1.0   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00     1.0   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00     1.0   \n",
       "\n",
       "   waterfront  condition  grade  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0           0          3      7      1955             0    98178  47.5112   \n",
       "1           0          3      7      1951          1991    98125  47.7210   \n",
       "2           0          3      6      1933             0    98028  47.7379   \n",
       "3           0          5      7      1965             0    98136  47.5208   \n",
       "4           0          3      8      1987             0    98074  47.6168   \n",
       "\n",
       "      long  \n",
       "0 -122.257  \n",
       "1 -122.319  \n",
       "2 -122.233  \n",
       "3 -122.393  \n",
       "4 -122.045  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"./data/kc_house_data.csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid: 집 고유아이디\\ndate: 집이 팔린 날짜 \\nprice: 집 가격 (타겟변수)\\nbedrooms: 주택 당 침실 개수\\nbathrooms: 주택 당 화장실 개수\\nfloors: 전체 층 개수\\nwaterfront: 해변이 보이는지 (0, 1)\\ncondition: 집 청소상태 (1~5)\\ngrade: King County grading system 으로 인한 평점 (1~13)\\nyr_built: 집이 지어진 년도\\nyr_renovated: 집이 리모델링 된 년도\\nzipcode: 우편번호\\nlat: 위도\\nlong: 경도\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "<집 값 예측> - 'Boston house' data와는 다른 데이터\n",
    "\n",
    "id: 집 고유아이디\n",
    "date: 집이 팔린 날짜 \n",
    "price: 집 가격 (타겟변수)\n",
    "bedrooms: 주택 당 침실 개수\n",
    "bathrooms: 주택 당 화장실 개수\n",
    "floors: 전체 층 개수\n",
    "waterfront: 해변이 보이는지 (0, 1)\n",
    "condition: 집 청소상태 (1~5)\n",
    "grade: King County grading system 으로 인한 평점 (1~13)\n",
    "yr_built: 집이 지어진 년도\n",
    "yr_renovated: 집이 리모델링 된 년도\n",
    "zipcode: 우편번호\n",
    "lat: 위도\n",
    "long: 경도\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncar : 21613 \n",
      " nvar : 14\n"
     ]
    }
   ],
   "source": [
    "ncar = data.shape[0] # 데이터 개수\n",
    "nvar = data.shape[1] # 변수 개수\n",
    "print('ncar : %d' % ncar, '\\n', 'nvar : %d' % nvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의미가 없다고 판단되는 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id', 'date', 'zipcode', 'lat', 'long'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 범주형 변수를 이진형 변수로 변환\n",
    "- 범주형 변수는 waterfront 컬럼 뿐이며, 이진 분류이기 때문에 0, 1로 표현한다.\n",
    "- 데이터에서 0, 1로 표현되어 있으므로 과정 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설명변수와 타겟변수를 분리, 학습데이터와 평가데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15129, 8) (6484, 8) (15129,) (6484,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['price'])) # Price를 제외한 모든 행\n",
    "X = data[feature_columns]\n",
    "y = data['price']\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 7:3\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # 데이터 개수 확인\n",
    "# 학습 데이터 : 약 15000개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터를 선형 회귀 모형에 적합 후 평가 데이터로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.595</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.595</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2776.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Mar 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:05:11</td>     <th>  Log-Likelihood:    </th> <td>-2.0826e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15129</td>      <th>  AIC:               </th>  <td>4.165e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15120</td>      <th>  BIC:               </th>  <td>4.166e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td> 7.186e+06</td> <td> 1.73e+05</td> <td>   41.548</td> <td> 0.000</td> <td> 6.85e+06</td> <td> 7.52e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms</th>    <td> 1.303e+05</td> <td> 3960.833</td> <td>   32.889</td> <td> 0.000</td> <td> 1.23e+05</td> <td> 1.38e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms</th>     <td>-2224.7910</td> <td> 2382.356</td> <td>   -0.934</td> <td> 0.350</td> <td>-6894.497</td> <td> 2444.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition</th>    <td> 1.641e+04</td> <td> 3169.013</td> <td>    5.178</td> <td> 0.000</td> <td> 1.02e+04</td> <td> 2.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors</th>       <td> 1946.3052</td> <td> 4336.838</td> <td>    0.449</td> <td> 0.654</td> <td>-6554.422</td> <td> 1.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade</th>        <td> 1.956e+05</td> <td> 2199.540</td> <td>   88.924</td> <td> 0.000</td> <td> 1.91e+05</td> <td>    2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront</th>   <td> 7.555e+05</td> <td> 2.26e+04</td> <td>   33.479</td> <td> 0.000</td> <td> 7.11e+05</td> <td>    8e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>     <td>-4300.7865</td> <td>   88.073</td> <td>  -48.832</td> <td> 0.000</td> <td>-4473.420</td> <td>-4128.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_renovated</th> <td>   12.7325</td> <td>    5.043</td> <td>    2.525</td> <td> 0.012</td> <td>    2.847</td> <td>   22.618</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13447.374</td> <th>  Durbin-Watson:     </th>  <td>   1.994</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1684794.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.763</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>54.147</td>   <th>  Cond. No.          </th>  <td>1.82e+05</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.82e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.595\n",
       "Model:                            OLS   Adj. R-squared:                  0.595\n",
       "Method:                 Least Squares   F-statistic:                     2776.\n",
       "Date:                Sat, 21 Mar 2020   Prob (F-statistic):               0.00\n",
       "Time:                        15:05:11   Log-Likelihood:            -2.0826e+05\n",
       "No. Observations:               15129   AIC:                         4.165e+05\n",
       "Df Residuals:                   15120   BIC:                         4.166e+05\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const         7.186e+06   1.73e+05     41.548      0.000    6.85e+06    7.52e+06\n",
       "bathrooms     1.303e+05   3960.833     32.889      0.000    1.23e+05    1.38e+05\n",
       "bedrooms     -2224.7910   2382.356     -0.934      0.350   -6894.497    2444.915\n",
       "condition     1.641e+04   3169.013      5.178      0.000    1.02e+04    2.26e+04\n",
       "floors        1946.3052   4336.838      0.449      0.654   -6554.422    1.04e+04\n",
       "grade         1.956e+05   2199.540     88.924      0.000    1.91e+05       2e+05\n",
       "waterfront    7.555e+05   2.26e+04     33.479      0.000    7.11e+05       8e+05\n",
       "yr_built     -4300.7865     88.073    -48.832      0.000   -4473.420   -4128.153\n",
       "yr_renovated    12.7325      5.043      2.525      0.012       2.847      22.618\n",
       "==============================================================================\n",
       "Omnibus:                    13447.374   Durbin-Watson:                   1.994\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1684794.827\n",
       "Skew:                           3.763   Prob(JB):                         0.00\n",
       "Kurtosis:                      54.147   Cond. No.                     1.82e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.82e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "sm_train_x = sm.add_constant(train_x, has_constant=\"add\") # 상수항 추가\n",
    "sm_model = sm.OLS(train_y, sm_train_x)\n",
    "fitted_sm_model = sm_model.fit()\n",
    "fitted_sm_model.summary()\n",
    "\n",
    "# R-squared : y의 총 변동성 분의 x가 설명하는 변동의 비율 -> 약 60%\n",
    "# bathrooms 수 많으면 집값 올라감, bedrooms 수 많으면 집값 떨어짐\n",
    "\n",
    "'''\n",
    "기존 강사님 code\n",
    "\n",
    "regression_model = LinearRegression() # 선형 회귀 모형\n",
    "linear_model1 = regression_model.fit(train_x, train_y) # 학습 데이터를 선형 회귀 모형에 적합\n",
    "predict1 = linear_model1.predict(test_x) # 학습된 선형 회귀 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict1, test_y)))) # RMSE 결과\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyun\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 예측을 해보자\n",
    "sm_test_x = sm.add_constant(test_x, has_constant=\"add\") # test할 데이터만들기, test 데이터에도 상수항 추가\n",
    "sm_model_predict = fitted_sm_model.predict(sm_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239804.29670858168"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(sm_model_predict, test_y)) # 하나의 모델만 사용했을 때 RMSE\n",
    "# 굉장히 큰 값\n",
    "# 이따가 다른 모델과 MSE값 비교해볼건데 지금 상태로는 비교하기 쉽지않아서 루트씌우자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging한 결과가 일반적인 결과보다 좋은지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9511\n",
      "241128.38173926383\n",
      "9542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyun\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\hyun\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239764.76895080705\n",
      "9572\n",
      "240452.83687778324\n",
      "9562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyun\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\hyun\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\hyun\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240799.3924695097\n",
      "9545\n",
      "239652.70723645116\n",
      "9552\n",
      "240651.52607320354\n",
      "9507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyun\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\hyun\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "239703.37733402164\n",
      "9529\n",
      "239947.3382701117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyun\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\Users\\hyun\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9535\n",
      "239931.53957328343\n",
      "9574\n",
      "240369.15494944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyun\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Bagging을 할 수 있는 라이브러리 패키지가 있어서 그거 사용하면되는데\n",
    "# 일단 처음이니까 for문 이용해서 앙상블하는 코드 작성해보자\n",
    "# 변수를 좀 다르게 추출한다거나 다른 기법 사용하기 편하기때문에 직접 for문 사용하는 것도 좋다\n",
    "\n",
    "bagging_predict_result = []\n",
    "for _ in range(10):\n",
    "    data_index = [data_index for data_index in range(train_x.shape[0])] # 1부터 train_x 개수만큼 데이터 가져와\n",
    "    random_data_index = np.random.choice(data_index, train_x.shape[0]) # 데이터 복원추출 (추출할 변수:data_index, 추출할 요소의 개수:train_x.shape[0])\n",
    "    print(len(set(random_data_index)))\n",
    "    # set() : ex) set([1, 1, 3, 2, 4, 1]) = 1, 2, 3, 4 \n",
    "    # unique한 것만 추출\n",
    "    # 학습데이터 약 15000개 중 unique한 데이터는 약 9500~9600개 => 데이터 중 약 63%만 추출되는 게 맞지\n",
    "    \n",
    "    sm_train_x = train_x.iloc[random_data_index] # 복원추출 된 학습데이터 가져와서 다시 fitting시키는 과정 시행\n",
    "    sm_train_y = train_y.iloc[random_data_index] # y도 똑같이 가져와야겠지\n",
    "    sm_train_x = sm.add_constant(sm_train_x, has_constant=\"add\")\n",
    "    sm_model = sm.OLS(sm_train_y, sm_train_x)\n",
    "    fitted_sm_model = sm_model.fit()\n",
    "    pred = fitted_sm_model.predict(sm_test_x) # test할 데이터 위에서 만들었으므로 갖다쓰기\n",
    "    bagging_predict_result.append(pred) # 결과값 append\n",
    "    print(sqrt(mean_squared_error(pred, test_y)))\n",
    "    \n",
    "# MSE : 이전에 전체 데이터 다 쓴 경우보다 아주 조금 높게 나왔음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735      5.651988e+05\n",
       "2830     7.255256e+05\n",
       "4106     1.112184e+06\n",
       "16218    1.479253e+06\n",
       "19964    6.971432e+05\n",
       "             ...     \n",
       "12606    6.080202e+05\n",
       "14393    6.916773e+05\n",
       "6899     3.207711e+05\n",
       "85       9.062189e+05\n",
       "21363    4.294984e+05\n",
       "Length: 6484, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict_result[1] # 데이터 복원추출했을 때의 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n(1~n)번째 리스트에 있는 첫번째 값들을 각각 다 더하고 평균을 내야 최종적인 ensemble 예측값 나오겠지\n",
    "bagging_predict = []\n",
    "for lst2_index in range(test_x.shape[0]): # test 데이터 개수만큼 반복\n",
    "    # lst2_index : 데이터의 index\n",
    "    temp_predict = [] # 임시 리스트\n",
    "    for lst_index in range(len(bagging_predict_result)):\n",
    "        # bagging_predict_result[1], bagging_predict_result[2], bagging_predict_result[3] 등등 데이터 가져와서 append-> 평균값\n",
    "        temp_predict.append(bagging_predict_result[lst_index].values[lst2_index])\n",
    "    bagging_predict.append(np.mean(temp_predict))\n",
    "    # for문 다 돌면 이젠 bagging_predict_result[1]의 두번째 값, bagging_predict_result[2]의 두번째 값\n",
    "    # 등등 또 append 시켜서 평균값 구하는 거 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239988.8077716596"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균내서 predict 값 내기\n",
    "sqrt(mean_squared_error(bagging_predict, test_y))\n",
    "# for문 이용해서 bagging했을 때 ensenble 모델의 평균적인 RMSE\n",
    "# 하나의 모델만 사용했을 때의 RMSE보다 증가했지 -> 오히려 더 안좋은 결과가 나왔음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터를 선형 회귀 모형에 적합 후 평가 데이터로 검증(Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regression_model = LinearRegression()\n",
    "linear_model1 = regression_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 을 이용하여 선형 회귀 모형에 적합 후 평가 (Sampling 10번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239913.68717400832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# 패키지 이용해서 bagging 실습\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging_model = BaggingRegressor(base_estimator = regression_model, # 선형회귀모형\n",
    "                                 n_estimators=5,# 5번 샘플링\n",
    "                                 verbose = 1) # 학습 과정 표시\n",
    "linear_model2 = bagging_model.fit(train_x, train_y)# 학습 진행\n",
    "predict2 = linear_model2.predict(test_x) # 학습된 Bagging 선형 회귀 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict2, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그렇다면 Sampling을 많이 해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239830.76688097368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "bagging_model2 = BaggingRegressor(base_estimator = regression_model, # 선형 회귀모형\n",
    "                                  n_estimators = 30, # 30번 샘플링\n",
    "                                  verbose = 1) # 학습 과정 표시\n",
    "linear_model3 = bagging_model2.fit(train_x, train_y) # 학습 진행\n",
    "predict3 = linear_model3.predict(test_x) # 학습된 Bagging 선형 회귀 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict3, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터를 의사결정나무모형에 적합 후 평가 데이터로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 296114.43756303575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decision_tree_model = DecisionTreeRegressor() # 의사결정나무 모형\n",
    "tree_model = decision_tree_model.fit(train_x, train_y) # 학습 데이터를 의사결정나무 모형에 적합\n",
    "predict_tree = tree_model.predict(test_x) # 학습된 의사결정나무 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict_tree, test_y)))) # RMSE 결과 (test 데이터에 대한)\n",
    "\n",
    "# 성능이 굉장히 안좋아졌지\n",
    "# 오히려 회귀모델 하나 적합시키는 게 훨씬 더 좋을 결과.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9504\n",
      "299722.1939446347\n",
      "9578\n",
      "301004.5606818526\n",
      "9595\n",
      "280100.290822849\n",
      "9549\n",
      "302763.75482187513\n",
      "9536\n",
      "305106.8934695088\n",
      "9533\n",
      "293515.2077458066\n",
      "9615\n",
      "297869.803692905\n",
      "9576\n",
      "290049.18113542284\n",
      "9639\n",
      "307084.0288660091\n",
      "9593\n",
      "271399.9676319777\n"
     ]
    }
   ],
   "source": [
    "# 다시 for문 이용\n",
    "\n",
    "bagging_predict_result = []\n",
    "for _ in range(10):\n",
    "    data_index = [data_index for data_index in range(train_x.shape[0])]\n",
    "    random_data_index = np.random.choice(data_index, train_x.shape[0])\n",
    "    print(len(set(random_data_index)))\n",
    "    sm_train_x = train_x.iloc[random_data_index]\n",
    "    sm_train_y = train_y.iloc[random_data_index] \n",
    "    decision_tree_model = DecisionTreeRegressor()\n",
    "    tree_model = decision_tree_model.fit(sm_train_x, sm_train_y) \n",
    "    predict_tree = tree_model.predict(test_x)\n",
    "    bagging_predict_result.append(predict_tree) \n",
    "    print(sqrt(mean_squared_error(predict_tree, test_y)))\n",
    "    \n",
    "# tree 모델은 overfitting이 심하게 일어나서 지금 좋은 모델이 하나도 없어\n",
    "# 다 MSE값이 높잖아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_predict = []\n",
    "for lst2_index in range(test_x.shape[0]): # test 데이터 개수만큼 반복\n",
    "    # lst2_index : 데이터의 index\n",
    "    temp_predict = [] # 임시 리스트\n",
    "    for lst_index in range(len(bagging_predict_result)):\n",
    "        # bagging_predict_result[1], bagging_predict_result[2], bagging_predict_result[3] 등등 데이터 가져와서 append-> 평균값\n",
    "        temp_predict.append(bagging_predict_result[lst_index][lst2_index])\n",
    "        # 위 코드에서는 .values[]써서 value도 인덱스를 할당해서 가져왔어야했는데 이제는 array형태라 바로 [][]가능\n",
    "    bagging_predict.append(np.mean(temp_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236514.25175656882"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(bagging_predict, test_y))\n",
    "# 근데 모델들의 예측값을 평균냈더니 성능이 굉장히 좋아졌음\n",
    "# 이게 앙상블의 기본적인 컨셉!\n",
    "# 앙상블쓰면 성능 올라갈 확률이 높고, 그 base model은 overfitting이 잘 되는 게 일반적임\n",
    "# 그 이유는 test data에 대한 다양한 의견을 수렴하기위해서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 을 이용하여 의사결정나무모형에 적합 후 평가 (Sampling 10번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 237378.2649133019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "bagging_decision_tree_model1 = BaggingRegressor(base_estimator = decision_tree_model, # 의사결정나무 모형\n",
    "                                                n_estimators = 10, # 10번 샘플링\n",
    "                                                verbose = 1) # 학습 과정 표시\n",
    "tree_model2 = bagging_decision_tree_model1.fit(train_x, train_y) # 학습 진행\n",
    "predict2 = tree_model2.predict(test_x) # 학습된 Bagging 의사결정나무 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict2, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 을 이용하여 의사결정나무모형에 적합 후 평가 (Sampling 30번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 230753.69555253806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "bagging_decision_tree_model2 = BaggingRegressor(base_estimator = decision_tree_model, # 의사결정나무 모형\n",
    "                                                n_estimators = 30, # 30번 샘플링 (일반적으로 30번, 많이하면 50번)\n",
    "                                                verbose = 1) # 학습 과정 표시\n",
    "tree_model3 = bagging_decision_tree_model2.fit(train_x, train_y) # 학습 진행\n",
    "predict3 = tree_model3.predict(test_x) # 학습된 Bagging 의사결정나무 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict3, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
